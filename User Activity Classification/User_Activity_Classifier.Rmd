---
title: "Project-Final"
author: "Arvind Elangovan"
date: "December 9, 2017"
output: word_document
---

```{r}

#Library imports and installs
# install.packages("readr")
# install.packages("randomForest")
# install.packages("readxl")
# install.packages("MASS")
# install.packages("class")
# install.packages("boot")
# install.packages("e1071")
# install.packages("rnn")
# install.packages("plyr")
# install.packages("neuralnet")
library(readxl)
library(readr)
library(randomForest)
library(MASS)
library(class)
library(boot)
library("e1071")
library(rnn)
library(plyr)
library(neuralnet)
```

```{r}
#loading training sets
training_x <- read.table("./X_train.txt", header = FALSE)
train_x_df = as.data.frame(training_x)

training_response <- read.table("./Y_train.txt")
train_response_df = as.data.frame(training_response)
names(train_response_df) = "response"
train_response_df$response = as.factor(train_response_df$response)

#removing non-transformed data
rm(training_x)
rm(training_response)

#creating dataset of x and y combined
train_df = cbind(train_x_df,train_response_df)

```

```{r}
#loading testing data sets
testing_x <- read.table("./X_test.txt", header = FALSE)
test_x_df = as.data.frame(testing_x)

testing_response <- read.table("./Y_test.txt")
test_response_df = as.data.frame(testing_response)
names(test_response_df) = "response"
test_response_df$response = as.factor(test_response_df$response)



#removing non-transformed data
rm(testing_x,testing_response)

```

```{r}
#configuring the output to be capable of prinitng all output lines
options(max.print = 12000)
```

```{r}
#implementing random forest on the data set
hapt_randomForest = randomForest(train_df$response ~ ., data=train_df, mtry=24 ,importance= TRUE)
hapt_randomForest$importance
```

```{r}
#We exported the above numbers we got from randomforest$importance into an excel sheet which is being imported below
Importance <- read_excel("./Importance.xlsx")
importance_sorted = Importance[order(-Importance$`%IncMSE`),]
rm(Importance)
```

```{r}
#We selected the Highest values for %IncMSE and set the bar at zero. Leaving us with 353 predictors to create a random forest model

model_params = head(importance_sorted$Parameter,353)
predictors= paste(model_params, sep = "+")

model_expression = formula(paste("response~",paste(predictors,collapse = "+")))
rm(predictors,model_params)
```

```{r}
#Making training dataset with 353 important columns
Importance <- read_excel("./Importance.xlsx")
importance_sorted = Importance[order(-Importance$`%IncMSE`),]
model_params_353 = head(importance_sorted$Parameter,353)
predictors_353= paste(model_params_353, sep = "+")
X_train_353 = train_x_df[,predictors_353]
train_353 = cbind(X_train_353,response = train_response_df$response)
write.csv(X_train_353,"train_353.csv")

```


```{r}
#Making testing dataset with 353 important columns
Importance <- read_excel("./Importance.xlsx")
importance_sorted = Importance[order(-Importance$`%IncMSE`),]
model_params_353_test = head(importance_sorted$Parameter,353)
predictors_353= paste(model_params_353_test, sep = "+")
X_test_353 = test_x_df[,predictors_353]
write.csv(X_test_353,"test_353.csv")

#removing unused variables
rm(Importance,importance_sorted)
```



```{r}
#building a random forest model for top 353 predictors
hapt_randomForest_model_353 = randomForest(model_expression,data = train_df, mtry=19, importance = TRUE)
summary(hapt_randomForest_model_353)

#Making predictions on Test data using above Random Forest model
yhat.rf_model_353 = predict(hapt_randomForest_model_353, newdata = test_x_df)

#Checking prediction power of the model
classification = yhat.rf_model_353 == test_response_df$response
classification_rate = sum(classification)/length(classification) 
classification_rate


table(test_response_df$response, yhat.rf_model_353)

```

```{r}
#Implementing PCA on the dataset with 353 predictors selected after randomforest$importance
#train_353 <- read_csv("./train_353.csv")
attach(X_train_353)
pr.out = prcomp(X_train_353, scale = TRUE)
#names(pr.out)
pc.var = pr.out$sdev^2
pc.pvar = pc.var/sum(pc.var)
options(max.print = 100000)
#pr.out$center
#pr.out$scale
#pr.out$rotation
dim(pr.out$x)
```

```{r}
#Plotting 
plot(cumsum(pc.pvar), xlab = "Prinicpal component", ylab = "Cumulative Proportion of variance explained", type ='b', main = "Prinicpal component proportions", col="red")
abline(h=0.95)
abline(v=45)
```

```{r}
#first 45 principal components explain 95% of the variance in the response   
#Selecting the PC1 to PC45 prinicpal compenents from original data set

train_45_pca = data.frame(response = train_df$response, pr.out$x)
train_45_pca = train_45_pca[,1:46]
train_45_pca$response = as.factor(train_45_pca$response)

#transforming test data for PCA
test.45_pca = predict(pr.out, newdata =X_test_353 )
test.45_pca = as.data.frame(test.45_pca)
test.45_pca = test.45_pca[,1:45]

```

```{r}
##Implementing random forest with predictors from PCA

hapt_pca_rf_model = randomForest(response ~ .,data = train_45_pca, mtry=7, importance = TRUE)
summary(hapt_pca_rf_model)

#Making predictions on Test data using above Random Forest model
yhat.rf_pca = predict(hapt_pca_rf_model, newdata = test.45_pca)

#Checking prediction power of the model
classification = yhat.rf_pca == test_response_df$response
classification_rate = sum(classification)/length(classification)
classification_rate

table(test_response_df$response, yhat.rf_pca)

```
```{r}
##removing unused datasets with 561 predictors
rm(train_df,train_x_df)
```


```{r}
##LDA using 45 predictors determined by PCA

hapt_lda_45 = lda(response ~ ., data = train_45_pca)

pred_lda_45 = predict(hapt_lda_45, newdata =  test.45_pca)

#Confusion matrix for the model
table(pred_lda_45$class, test_response_df$response)

#Accuracy of the model
1- mean(pred_lda_45$class != test_response_df$response)


##LDA using 353 predictors determined by randomforest$importance
hapt_lda_353 = lda(response ~ ., data = train_353)

pred_lda_353 = predict(hapt_lda_353, newdata =  test_x_df)

#Confusion matrix for the model
table(pred_lda_353$class, test_response_df$response)

#Accuracy of the model
1- mean(pred_lda_353$class != test_response_df$response)

```

```{r}
##QDA using 45 predictors determined by PCA
#hapt_qda_45 = qda(response ~ ., data = train_45_pca)


#hapt_qda_353 = qda(response ~ ., data = train_353)

#QDA could not be performed on the training data set as some classes like 10,11,12 did not have enough data points for QDA to train the model

```

```{r}
##K = 10

##KNN using 45 predictors determined by PCA
library(class)
train_45_pca_forKNN = train_45_pca[2:ncol(train_45_pca)]


pred_knn_45 = knn(train_45_pca_forKNN, test.45_pca, train_45_pca$response, k=10)

#Confusion matrix for the model
table(pred_knn_45, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_45 != test_response_df$response)


##KNN using 353 predictors determined by randomforest$importance
pred_knn_353 = knn(X_train_353, X_test_353 , train_response_df$response, k=10)

#Confusion matrix for the model
table(pred_knn_353, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_353 != test_response_df$response)
```


```{r}

## K = 20
##KNN using 45 predictors determined by PCA
pred_knn_45 = knn(train_45_pca_forKNN, test.45_pca, train_45_pca$response, k=20)

#Confusion matrix for the model
table(pred_knn_45, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_45 != test_response_df$response)

##KNN using 353 predictors determined by randomforest$importance
pred_knn_353 = knn(X_train_353, X_test_353 , train_response_df$response, k=20)

#Confusion matrix for the model
table(pred_knn_353, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_353 != test_response_df$response)
```


```{r}

## K = 50
##KNN using 45 predictors determined by PCA
pred_knn_45 = knn(train_45_pca_forKNN, test.45_pca, train_45_pca$response, k=50)

#Confusion matrix for the model
table(pred_knn_45, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_45 != test_response_df$response)

##KNN using 353 predictors determined by randomforest$importance
pred_knn_353 = knn(X_train_353, X_test_353 , train_response_df$response, k=50)

#Confusion matrix for the model
table(pred_knn_353, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_353 != test_response_df$response)

```

```{r}
## K = 100
##KNN using 45 predictors determined by PCA
pred_knn_45 = knn(train_45_pca_forKNN, test.45_pca, train_45_pca$response, k=100)

#Confusion matrix for the model
table(pred_knn_45, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_45 != test_response_df$response)

##KNN using 353 predictors determined by randomforest$importance
pred_knn_353 = knn(X_train_353, X_test_353 , train_response_df$response, k=100)

#Confusion matrix for the model
table(pred_knn_353, test_response_df$response)

#Accuracy of the model
1- mean(pred_knn_353 != test_response_df$response)
```

```{r}

knn.final.50 = rep(0,50)
for(i in 1:10){
  set.seed(i)
knn.error.50 = rep(0,50)
for(j in 1:50){
  knn.pred = knn(X_train_353, X_test_353 , train_response_df$response, k=j)
  knn.error = mean(knn.pred != test_response_df$response)
  knn.error.50[j] = knn.error
}
knn.final.50 = knn.final.50 + knn.error.50
}
knn.final.error.50 = knn.final.50/10
knn.final.error.50

#K = 9 gives 0.1206831

```

```{r}

##SVM using 45 predictors determined by PCA

hapt_svm_45 = svm(response ~ ., data = train_45_pca)

pred_svm_45 = predict(hapt_svm_45, newdata =  test.45_pca)

#Confusion matrix for the model
table(pred_svm_45, test_response_df$response)

#Accuracy of the model
1- mean(pred_svm_45 != test_response_df$response)


##SVM using 353 predictors determined by randomforest$importance
hapt_svm_353 = svm(response ~ ., data = train_353)

pred_svm_353 = predict(hapt_svm_353, newdata =  test_x_df)

#Confusion matrix for the model
table(pred_svm_353, test_response_df$response)

#Accuracy of the model
1- mean(pred_svm_353 != test_response_df$response)

```


```{r}
#Creating dataset for Neural Netowrk

#loading training sets
training_x_nn <- read_csv("./train_353.csv")
train_x_df_nn = as.data.frame(training_x_nn)

training_response_nn <- read.table("./Y_train.txt")
train_response_df_nn = as.data.frame(training_response_nn)
names(train_response_df_nn) = "response"
train_response_df_nn$response = as.factor(train_response_df_nn$response)

rm(training_x_nn,training_response_nn)

#loading testing data sets
testing_x_nn <- read_csv("./test_353.csv")
test_x_df_nn = as.data.frame(testing_x_nn)

testing_response_nn <- read.table("./Y_test.txt")
test_response_df_nn = as.data.frame(testing_response_nn)
names(test_response_df_nn) = "response"
test_response_df_nn$response = as.factor(test_response_df_nn$response)

#removing non-transformed data
rm(testing_x_nn,testing_response_nn)

#Scaling
maxs <- apply(train_x_df_nn, 2, max) 
mins <- apply(train_x_df_nn, 2, min)


#Scaling training data
scaled_train_x <- as.data.frame(scale(train_x_df_nn, center = mins, scale = maxs - mins))

#Scaling testing data
scaled_test_x <- as.data.frame(scale(test_x_df_nn, center = mins, scale = maxs - mins))

#Binarizing the categorical output
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "1")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "2")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "3")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "4")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "5")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "6")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "7")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "8")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "9")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "10")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "11")
scaled_train_x = cbind(scaled_train_x,train_response_df_nn$response == "12")
names(scaled_train_x)[354:365] = c('R1','R2','R3','R4','R5','R6','R7','R8','R9','R10','R11','R12')


Importance <- read_excel("./Importance.xlsx")
importance_sorted = Importance[order(-Importance$`%IncMSE`),]
rm(Importance)


#We selected the Highest values for %IncMSE and set the bar at zero. Leaving us with 353 predictors to create a random forest model

model_params_nn = head(importance_sorted$Parameter,353)
predictors_nn <- as.formula(paste("R1+R2+R3+R4+R5+R6+R7+R8+R9+R10+R11+R12~", paste(model_params_nn[!model_params_nn %in% "R1+R2+R3+R4+R5+R6+R7+R8+R9+R10+R11+R12"], collapse = " + ")))

#Creating neural network model
nn = neuralnet(predictors_nn,data = scaled_train_x, hidden = c(235), act.fct = "logistic", linear.output = F)

```

```{r}
#Predicting using the neural network model

comp = compute(nn, scaled_test_x)
pred.weights = comp$net.result
idx = apply(pred.weights, 1, which.max)
pred = c('R1','R2','R3','R4','R5','R6','R7','R8','R9','R10','R11','R12')[idx]


test_response_df_nn$response = as.factor(test_response_df_nn$response)

test_response_df_nn$response = revalue(test_response_df_nn$response, c("1" = "R1","2" = "R2","3" = "R3","4" = "R4","5" = "R5","6" = "R6","7" = "R7","8" = "R8","9" = "R9","10" = "R10","11" = "R11","12" = "R12"))


#Confusion matrix for the model
table(cbind(pred), test_response_df_nn$response)

#Accuracy of the model
1- mean(cbind(pred) != test_response_df_nn$response)

```



